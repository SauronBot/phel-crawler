(ns phel-crawler\main
  (:require phel-crawler\modules\crawler :as crawler)
  (:require smeghead\getopt\getopt :refer [getopt]))

(defn- print-usage []
  (println "Usage: phel run src/main.phel <url> [options]\n")
  (println "Options:")
  (println "  --max-pages N    Max pages to crawl     (default: 50)")
  (println "  --max-depth N    Max link depth          (default: 2)")
  (println "  --concurrency N  Concurrent requests     (default: 5)")
  (println "  --timeout N      Request timeout seconds (default: 10)")
  (println "  --all-domains    Follow links to other domains\n")
  (println "Example:")
  (println "  phel run src/main.phel https://example.com --max-pages 50 --max-depth 2"))

(defn- truncate [s n]
  (if (> (php/strlen s) n)
    (str (php/substr s 0 (- n 3)) "...")
    s))

(defn- run []
  (let [argv   (php/aget php/$_SERVER "argv")
        args   (php/array_slice argv 3)
        parsed (getopt args ["--max-pages:" "--max-depth:" "--concurrency:" "--timeout:" "--all-domains"])
        errors (get parsed :errors)
        opts   (get parsed :options)
        pos    (get parsed :args)
        url    (first pos)]

    (when (not (empty? errors))
      (foreach [e errors] (println (str "Error: " e)))
      (println "")
      (print-usage)
      (php/exit 1))

    (if (nil? url)
      (do (println "Error: URL is required.\n")
          (print-usage))
      (let [max-pages   (php/intval (get opts :max-pages "50"))
            max-depth   (php/intval (get opts :max-depth "2"))
            concurrency (php/intval (get opts :concurrency "5"))
            timeout     (php/intval (get opts :timeout "10"))
            same-domain (nil? (get opts :all-domains))
            crawl-opts  {:max-pages max-pages :max-depth max-depth
                         :concurrency concurrency :timeout timeout
                         :same-domain same-domain}
            start       (php/microtime true)]

        (println (str "\nCrawling: " url))
        (println (str "  max-pages=" max-pages
                      "  max-depth=" max-depth
                      "  concurrency=" concurrency))
        (println (php/str_repeat "-" 72))

        (crawler/crawl url crawl-opts
          (fn [page]
            (println (str "  [" (get page :status) "] d=" (get page :depth)
                          "  " (truncate (if (= (get page :title) "") "(no title)" (get page :title)) 50)))
            (println (str "       " (truncate (get page :url) 68))))
          (fn [summary]
            (let [elapsed (php/round (- (php/microtime true) start) 2)]
              (println (php/str_repeat "-" 72))
              (println (str "\nDone in " elapsed "s  |  pages: "
                            (get summary :pages)
                            "  visited: " (get summary :visited))))))))))

(when-not *build-mode*
  (when (not (php/defined "PHEL_CRAWLER_RUNNING"))
    (php/define "PHEL_CRAWLER_RUNNING" true)
    (run)))
